\documentclass[letterpaper, 11pt]{article}
\usepackage{amsmath,amssymb,amsthm,fullpage,placeins,textcomp, multirow, subcaption, listings, empheq,esint, bm, hyperref, enumitem}
\usepackage[noend]{algpseudocode}
\usepackage[]{algorithm}
\usepackage{booktabs}
\usepackage{tikz}
\usepackage{tkz-berge}
\usepackage{array}


\usepackage[letterpaper, margin=1in]{geometry}
\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}


\begin{document}
\title{CS/EE 144 Pandemaniac Report}
\author{Team kraftwerk \\Fabian Boemer, Jessica Li}
\date{\today}
\maketitle


\section{Introduction and Overview}
\subsection{Introduction}
The goal of pandemaniac is to compete against other teams to infect as many nodes of a given graph as possible. Each graph is undirected and unknown before the game begins. The only influence a team may have on any game is the selection of seed nodes. Teams develop methods to select the most ``influential'' seed nodes without overlapping, since nodes selected by more than one team is nullified.
\\\\
After seed nodes for both teams are determined, each graph is iterated upon until the coloring converges, or for 100-200 times otherwise. The graph provided for this project all converged, but some, as described in Section \ref{sec:counterexample} do not. In each iteration, nodes are colored, or recolored, based on the coloring of itself and its direct neighbors. A colored node contributes 1.5 votes to that color. A neighboring node contributes 1 vote to its color. An uncolored node does not get a vote. If a color wins a strict majority of the votes, then the node is converted. Otherwise, no change is made.
\\\\
Our team's efforts were directed towards beating the TA's seed selection algorithms during ``regular season.'' In this report, TA-less refers to the selection of fewer seed nodes than allotted; TA-degree refers to the selection of seed nodes based on highest degree; TA-more refers to the selection of more seed nodes than allotted. The seed selection criteria for TA-less and TA-more are not known. 
\\\\
All code was written in Python and utilized various Python packages, such as Networkx \cite{networkx} , Community \cite{community}, Matplotlib \cite{matplotlib}, and JSON. 
\subsection{Counterexample} \label{sec:counterexample}
In some cases, a set of initial colorings may result in a game which fails to converge. Consider the complete bipartite graph, $K_{m,n}$, $m,n \geq 2$ with disjoint nodesets $U, V$ and initial colorings red $A=U$, blue $B=V$. Under this inial coloring, the direct neighbors of each node are nodes of the other color. In other words, nodes of the same color are not direclty connected. 
\\\\
In the first iteration, $A$-colored nodes will be converted to the color of the nodes in $V$ and $B$-colored nodes will be converted to the color of nodes in $U$. For all following timesteps, the colorings will continue to alternate between the bipartite sets. Figure \ref{fig:converge} shows the behavior of this game, which fails to converge.

\begin{figure}[h!]   
\begin{center}
\tikzstyle{every node}=[circle, draw, fill=black, minimum width=10pt]
\begin{subfigure}{.49\textwidth}
\begin{tikzpicture}
\foreach \x in {-2,-1,0,1,2}
	\foreach \y in {-1,0,1}{
		\draw (2*\y,0) -- (2*\x,2);
	}
	\foreach \x in {-2,-1,0,1,2}{
		\node[blue,circle,inner sep=1pt,fill] at (2*\x,2) {};
	}
	\foreach \x in {-1,0,1}{
		\node[red,circle,inner sep=1pt,fill] at (2*\x,0) {};
	}
\end{tikzpicture}
\caption{Graph at $t\mod 2 = 0$}
\end{subfigure} \\
\begin{subfigure}{.49\textwidth}
\begin{tikzpicture}
\foreach \x in {-2,-1,0,1,2}
	\foreach \y in {-1,0,1}{
		\draw (2*\y,0) -- (2*\x,2);
	}
	\foreach \x in {-2,-1,0,1,2}{
		\node[red,circle,inner sep=1pt,fill] at (2*\x,2) {};
	}
	\foreach \x in {-1,0,1}{
		\node[blue,circle,inner sep=1pt,fill] at (2*\x,0) {};
	}
\end{tikzpicture}
\caption{Graph at $t\mod 2 = 1$}
\end{subfigure}
\caption{Example of a graph and initial coloring that fails to converge}
\label{fig:converge}
\end{center}

\end{figure}



\section{Visualization}
Visualization was an important component of this project, useful for better understanding the graph's structure and how color propagated from selected seed nodes. We explored several built-in and custom visualizations provided in Networkx. 
\\\\
We attempted to visualize the clustering/community structure of the graph, using Networkx's visualization and Community's built-in partition functions. Nodes were sorted and colored based on community. The graph was then displayed using Networkx's ``spring layout'', which uses Fruchterman-Reingold force-directed algorithm. Nodes modeled as having repulsive forces and edges are modeled as spring. A balance of these forces allows the graph to be laid out with as few overlapping edges as possible. Figure \ref{fig:visualization} shows a coloring of graph clusters. Clusters are distinguishable, though not clearly separable.
\begin{figure}[h]
\begin{center}
\begin{subfigure}{.49\textwidth}
\includegraphics[width=\textwidth]{{day5_figs/2.10.32}.png}
\caption{Spring layout of graph clusters.}
\end{subfigure}
\begin{subfigure}{.49\textwidth}
\includegraphics[width=\textwidth]{{day1_figs/2.10.10.json_iter_1}.png}
\caption{Grid layout}
\end{subfigure}
\caption{Visualization of graphs 2.10.32 and 2.10.31}
\label{fig:visualization}
\end{center}
\end{figure}
\\\\
To see color propagation, we generated our own visualizer, in place of the non-functioning one. One criterion for visualizing color progression was maintaining a consistent graph between iterations. A circular layout was not instructive because nodes were too close together. We implemented a custom grid layout, as in Figure \ref{fig:visualization} where each node is labeled with its degree. The grid layout failed to visually capture the structure of the graph, but was useful for viewing the progress of color cascades. We may reasonable indentify clusters based on on the color propagations.
\\\\
We only used visualization for offline learning. A more complete approach would be to human input to select seed nodes by "eyeballing" important nodes in clusters. However, we did not consider our visualization displayed graph structure well enough to implement this approach.


\section{Algorithms}
\subsection{Day 1: Cancellation}
The first approach was a naive cancellation approach designed to beat TA-degree. Knowing exactly how seed nodes were selected, we sought to negate all but the lowest-degree seed node and conquer the highest degree node. Algorithm \ref{alg:cancellation} gives the pseudocode for the cancellation approach.
\begin{algorithm}
\caption{Cancellation Algorithm}
\label{Cancellation}
\begin{algorithmic}[1]
\Procedure{Cancellation}{$G$, $n$}
\State Order the nodes by degree centrality
\State Select the $n-1$ nodes with highest degree centrality
\State Select the previously-unselected node adjacent to the vertex of highest-degree.
\State \textbf{return} selected nodes.
\EndProcedure
\end{algorithmic}
\label{alg:cancellation}
\end{algorithm} \\
Time constraints prevented us from testing this strategy before the Day 1 run. We retrospectively visualized the results from the Day 1 run against TA-degree, shown in Figure \ref{fig:cancellation}.
\begin{figure}[h!]
\begin{center}
\begin{subfigure}{.49\textwidth}
\includegraphics[width=\textwidth]{{day1_figs/2.10.10.json_iter_1}.png}
\caption{Iteration 1} \label{fig:cancellation:a}
\end{subfigure}
\begin{subfigure}{.49\textwidth}
\includegraphics[width=\textwidth]{{day1_figs/2.10.10.json_iter_2}.png}
\caption{Iteration 2} \label{fig:cancellation:b}
\end{subfigure}
\begin{subfigure}{.49\textwidth}
\includegraphics[width=\textwidth]{{day1_figs/2.10.10.json_iter_3}.png}
\caption{Iteration 3} \label{fig:cancellation:c}
\end{subfigure}
\begin{subfigure}{.49\textwidth}
\includegraphics[width=\textwidth]{{day1_figs/2.10.10.json_iter_4}.png}
\caption{Iteration 4} \label{fig:cancellation:d}
\end{subfigure}
\caption{Visualization of the Day 1 run against TA-degree. Our team's nodes are red; the TA's nodes are blue. The numbers in the nodes indicate the node degree.}
\label{fig:cancellation}
\end{center}
\end{figure}
In  Iteration 1, \ref{fig:cancellation:a}, we notice only one node of each color is selected, by construction. This implies all other nodes were negated. In Iteration 2,  \ref{fig:cancellation:b}, we claimed the highest degree node in this graph, the red node adjacent to the bottom-left corner with degree 139. However, the TA's blue seed node had a higher degree than our seed node and claimed several blue nodes. In Iteration 3, \ref{fig:cancellation:c}, we see the highest-degree node failed to convert many nodes. The TA already has spread to enough nodes that converting any new nodes is difficult. By Iteration 4, \ref{fig:cancellation:d}, it is clear the blue nodes have won. Thus, our cancellation approach moves too slowly. Controlling the highest-degree node at Iteration 2 is not enough to win against TA-degree.
\\\\
As simulated, we did not beat TA-degree on Day 1. We did, however, beat TA-fewer. Though not our intention, this was not unexpected, since the set of $n-1$ nodes with high degree centrality is a decent selection that conquers rapidly.

\subsection{Day 2: Centrality Measures}
On Day 2, we focused on developing a different strategy to beat TA-degree. We explored the several centrality measures built into NetworkX, including betweeness, current flow betweenness (cfbet), closeness, and eigenvector centrality. First we tried taking top $n$ most-important nodes for each centrality measure ranking. We excluded degree-centrality since TA-degree uses degree centrality. We modified ``sim.py'' to simulate each selction strategy against TA-degree. Table \ref{table:day2} shows the results of our simulations

\begin{table}\centering
\begin{tabular}{cccccc}
Day & Graph & Centrality measure & Strategy count & TA-degree count & Ratio \\ \hline
\toprule
\multirow{1}{*}{1}
& 2.10.10 & betweenness & 18 & 482 & 0.04 \\
& 2.10.10 & cfbet & 491 & 9 & 0.99 \\ 
& 2.10.10 & closeness & 386 & 113 & 0.77 \\
& 2.10.10 & eigenvector & 394 & 106 & 0.79\\ \cmidrule{2-6}

& 2.10.20 & betweenness & 43 & 455 & 0.08 \\
& 2.10.20 & cfbet & 43 & 455 & 0.08 \\ 
& 2.10.20 & closeness & 452 & 45 & 0.90\\
& 2.10.20 & eigenvector & 429 & 69 & 0.86\\ \cmidrule{2-6}

& 2.10.30 & closeness & 475 & 22 & 0.96\\
& 2.10.30 & eigenvector & 469 & 28 & 0.94\\
\midrule

\multirow{1}{*}{2}
& 2.10.11 & cfbet & 31 & 468 & 0.06\\
& 2.10.11 & closeness & 231 & 263 & 0.47 \\
& 2.10.11 & eigenvector & 239 & 256 & 0.48\\ \cmidrule{2-6}

& 2.10.21 & closeness & 277 & 216 & 0.56 \\
& 2.10.21 & eigenvector & 206 & 283 & 0.42\\ \cmidrule{2-6}

& 2.10.31 & closeness & 35 & 456 & 0.07 \\
& 2.10.31 & eigenvector & 28 & 464 & 0.056 \\
\bottomrule
\end{tabular}
\caption{Summary of local testing results for each centrality measure for Day 2.}
\label{table:day2}
\end{table}

This new method was tested on Day 1's TA-degree graph. We see in Table \ref{table:day2} that closeness and eigenvector centrality consistently outperformed TA-degree. For our submission, we set up a local pipeline to generate seeds for current flow betweeness, closeness, and eigenvector centralities, and simulate TA-degree against each centrality measure. We expeceted at least one of the three strategies to beat TA-degree on graph 2.10.11, based on the performances on graphs 2.10.10, 2.10.20, 2.10.30.
\\\\
Unfortunately, during submission, we simulated narrow losses against TA-degree with closeness and eigevector centralities, with a heavy loss with current-flow betweenness. The simulation was correct, as we failed to beat TA-degree.
\\\\
We spent some time trying to visualize the structure of the graphs. Unforunately, the visualizations produced by NetworkX's ``spring layout'' were inconsistent between successive drawings, and the remaining visualization formats did not expose the structure of the graph.
\\\\
We tried clustering the graph using NetworkX's, ``k\_components = apxa.k\_components(G).'' For 500-node graphs, the clustering took 129 seconds, which was deemed too long for the 3 minute deadline.

\subsection{Day 3: Monte-Carlo}
Having failed to beat TA-degree, we increased the scope of our approach. We explored several more unfamiliar measures of centrality, and began used multiple centrality measures for selecting a set of seeds. We included Katz centrality and dispersion centrality.
Katz centrality solves a system of linear equations for the centrality of a node relative to that of its neighbors \cite{networkx}.
Dispersion centrality measures how close are mutual friends between pairs of nodes in the graph \cite{networkx} % could also cite http://arxiv.org/pdf/1310.6753v1.pdf
In some sense, it is another measure of ``betweenness.''
\\\\
Because each of these centrality measures took only a few seconds, we were able to use our time more completely through Monte-Carlo simulations. Algorithm \ref{alg:promising} is the pseudocode for this approach.
\\\\
This was a non-disciminative approach, which does not distinguish between the efficacy of each centrality, nor the complementary advantages of each centrality measure. For example, nodes with high betweenness measure are likely prevent cascades from spreading, while nodes with high closeness centrality spread quickly to all nodes in a cluster. Nevertheless, this approach successfully generated several strategies simulated to win against TA-degree. Having not yet beat TA-more, we varied our final output among the top-10 best-performing strategies simulated to beat TA-more. This provides more variance in the seeding, and makes the seeding more robust against an adverserial TA seeding.
\\\\
As simulated, we successfully beat TA-degeree with this approach. However, we still failed to beat TA-more.

\begin{algorithm}
\caption{Promising Algorithm}
\begin{algorithmic}[1]
\Procedure{Promising}{$G$, $n$}
\State Order the nodes by degree centrality, eigenvector centrality, Katz centrality, closeness centrality, dispersion centrality.
\State Initialize dictionary $d$ with keys all the nodes and values as 0
\For{each centrality measure}
\For{node in top $n$ ranking}
\State Let $d[\text{node}] += n - $ ranking.
\EndFor
\EndFor
\State Sort $d$ descending by value and choose 12 highest-value nodes as 'promising'
\For{each of $12 \choose 10$ combinations of 10 seed nodes }
\State Simulate the seed against TA-degree
\EndFor
\State Order seeds by number of nodes claimed against TA-degree
\While{Final Seeding not complete}
\For{the top ten seeds ranked by performance}
\State populate Final Seeding with the ten seeds
\EndFor
\EndWhile
\EndProcedure
\State \textbf{return} Final Seeding.
\end{algorithmic}
\label{alg:promising}
\end{algorithm}

\subsection{Day 4: Blending}
The remainder of regular season was focused on beating TA-more. We refined our idea of blending promising nodes. We took the $n$ most promising nodes based on degree centrality, betweenness and eigenvector centrality. We reasoned that nodes with high degree centrality would effectively conquer clusters, while nodes with high betweeness would effectively blockade cascasdes from proceeding between clusters. Up to this point, eigenvector centrality performed quite well and was computed very rapidly, so we decided to include the nodes with high eigenvector centrality as well.

\begin{algorithm}
\caption{Hybrid Algorithm}
\begin{algorithmic}[1]
\Procedure{Hybrid}{$G$, $n$}
\State Order the nodes by degree centrality, eigenvector centrality, Katz centrality, closeness centrality, dispersion centrality.
\State Generate the set $s$ of top-$n$ ranked nodes in each centrality measure
\State Generate 100 random selections of $n$ nodes from $s$.
\For{each of 100 seed node selections}
\State Simulate seed nodes against TA-degree with $1.2n$ nodes.
\EndFor
\State \textbf{return} best-performing set of seed nodes.
\EndProcedure
\end{algorithmic}
\label{alg:hybrid}
\end{algorithm}

On the Day 4 run, we still failed to beat TA-more. Thus, the Monte-Carlo generation of ``important'' nodes failed to quickly cover enough variation in seed nodes to beat TA-more

\subsection{Day 5: Clustering}
On Day 5, we tried using the Louvain method \cite{louvain} based function provided in the Community package to partition the graph. This approach was much faster than than the previous approach using ``k\_components = apxa.k\_components(G).'' The size of the clusters varied from less than 10 to over 100 for a 500-node graph, and were not disjoint. We adapted previous approaches to clustering, described in Algorithm \ref{alg:cluster}.

\begin{algorithm}
\caption{Cluster Algorithm}
\begin{algorithmic}[1]
\Procedure{Hybrid}{$G$, $n$}
\State Cluster $G$ using Louvain method
\For{each cluster $c$}
\State Use promising($c$, $n$) to generate `most-important' node within the cluster.
\EndFor
\For{each of 3 populating strategies}
\State Initialize empty FinalSeeding list
\While{FinalSeeding length less than $n$}
\For{each cluster $c$}
\State Insert most-important node(s) from $c$ not yet in FinalSeeding
\EndFor
\State Simulate FinalSeeding against TA-more Day 4
\EndWhile
\EndFor
\State \textbf{return} best-performing FinalSeeding
\EndProcedure
\end{algorithmic}
\label{alg:cluster}
\end{algorithm}

\noindent For each cluster, we explored three methods of choosing the number of most-important node(s) selected. For a given cluster $c$, we populated FinalSeeding with the number of nodes proportional to one of:
\begin{enumerate}[label=(\arabic*)]
\item 1 (each cluster has the same number of nodes)
\item the total degree of nodes in $c$
\item the number of edges in $c$
\end{enumerate}

We simulated the results against the nodes picked by TA-more on previous days. Our findings are summarized in Table \ref{table:day5}.
\begin{table}[h!]\centering
\begin{tabular}{ccccc}
Graph & Strategy & Proportion Nodes Claimed & Games won \\ \hline
\toprule
2.10.30 & (1) & 0.13 & 5 \\
2.10.30 & (2) & 0.25 & 12 \\
2.10.30 & (3) & 0.07 & 1 \\
\midrule

2.10.31 & (1) & 0.04 & 0 \\
2.10.31 & (2) & 0.06 & 1 \\
2.10.31 & (3) & 0.04 & 0 \\
\midrule

2.10.32 & (1) & 0.60 & 47 \\
2.10.32 & (2) & 0.21 & 4 \\
2.10.32 & (3) & 0.21 & 7 \\
\midrule
\bottomrule
\end{tabular}
\caption{Summary of local testing results using clustering approach for Day 5.}
\label{table:day5}
\end{table}

\noindent We were able to win on graph 2.10.32, but did very poorly on graphs 2.10.30 and 2.10.31. We visualized and investigated the structure of the graphs to determined why this discrepency occurred.
\\\\
The visualization in Figure \ref{fig:day5} between graphs 2.10.31 and 2.10.32 suggested 2.10.32 was more clearly clustered than 2.10.31, suggesting our approach (1) works well for clustered graphs. This makes sense for clusters of roughly equal size. Nevertheless, we see 2.10.31 has a separate cluster of only 3 nodes, which is likely not worth placing a seed on. In retrospect, perhaps our strategies were placing too much weight on small clusters. Rather, perhaps, we should have chosen only nodes from the largest cluster.

\begin{figure}[h]
\begin{center}
\begin{subfigure}{.49\textwidth}
\includegraphics[width=\textwidth]{{day5_figs/2.10.31}.png}
\caption{2.10.31}
\end{subfigure}
\begin{subfigure}{.49\textwidth}
\includegraphics[width=\textwidth]{{day5_figs/2.10.32}.png}
\caption{2.10.32}
\end{subfigure}
\caption{Visualization of graphs 2.10.31 and 2.10.32}
\label{fig:day5}
\end{center}
\end{figure}
\par

\noindent In Table \ref{table:graphs} in Section \ref{appendix}, we see graph 2.10.32 has higher average and overall clustering coefficient, compared to graph 2.10.30, supporting the hypothesis that 2.10.32 is better clustered. 2.10.32 also a higher Louvain modularity, which means the Louvain method of clustering would produce better partitions on this graph. These results might suggest our approach (1) might only work well for graphs with these properties.
\\\\
Under time constraint, we decided to use the number of nodes proportional to the number in each cluster, since this was the only winning approach we discovered. Unfortunately, this failed to beat TA-more.

\section{Conclusion}

We explored various methods of selecting seed nodes and successfully beat TA-fewer and TA-degree. We did not manage to beat TA-more during regular season. Due to other commitments and time constraints, we did not actively participate in the tournament.
\par
We considered a few other approaches which were not implemented due to time-constraints. One approach was to explore parallel computation of centrality measures, which would have proven useful on the larger graphs. A different approach was using python's Gambit library \cite{gambit} to find Nash equilibria for a 2 (or more) player game. Given a graph $G = (V,E)$, we would construct an $n \times n$ zeros-sum payoff matrix, where $n = |V|$ with the payoff as some measure of importance, such as some combination of centrality measures. The multi-player Nash equilibrium would have generated better strategies for the tournament.
\\\\
We learned about other measures of centrality and exploring different combinations of centrality measures to ``cover up'' weaknesses. We learned to implement various Python packages associated with analyzing graphs and the runtime differences between functions. Our rudimentary implementation did not show clusters well, but did allow us to get a sense of spread of each color and graph structure. We learned the importance of documenting methods and results for sound scientific method as well as the importance of trying a broad set of approaches.

\pagebreak
\section{Appendix}\label{appendix}
\begin{table}[h!]\centering
\begin{tabular}{c | C{2.0cm} | C{2.0cm} | C{2.5cm} |C{1.7cm}|C{1.7cm}|C{1.7cm}|C{1.9cm}}
Graph & Average Clustering Coefficient & Overall Clustering Coefficient & Connected Components & Maximal Diameter & Average Diameter & Partitions & 
Louvain Modularity \\ \hline
2.10.30 & 0.44 & 0.28 & 2 & 6 & 2.61 & 7.0 & 0.35\\
2.10.31 & 0.46 & 0.28 & 2 & 7 & 2.65 & 10.0 & 0.34\\
2.10.32 & 0.51 & 0.36 & 1 & 6 & 2.83 & 8.0 & 0.5\\
2.10.33 & 0.47 & 0.3 & 1 & 7 & 2.61 & 12.0 & 0.34\\
2.10.34 & 0.48 & 0.27 & 1 & 7 & 2.83 & 8.0 & 0.47\\ \hline

2.10.20 & 0.42 & 0.29 & 1 & 7 & 2.78 & 9.0 & 0.4\\
2.10.21 & 0.53 & 0.36 & 2 & 7 & 2.87 & 11.0 & 0.48\\
2.10.22 & 0.47 & 0.29 & 1 & 7 & 2.58 & 6.0 & 0.38\\
2.10.23 & 0.47 & 0.3 & 1 & 6 & 2.53 & 6.0 & 0.36\\
2.10.24 & 0.48 & 0.31 & 1 & 6 & 2.64 & 9.0 & 0.36\\ \hline

2.10.10 & 0.48 & 0.31 & 1 & 6 & 2.55 & 7.0 & 0.4\\
2.10.11 & 0.51 & 0.32 & 1 & 8 & 2.68 & 8.0 & 0.33\\
2.10.12 & 0.52 & 0.36 & 1 & 7 & 2.93 & 5.0 & 0.45\\
2.10.13 & 0.5 & 0.33 & 1 & 6 & 2.95 & 9.0 & 0.49\\
2.10.14 & 0.5 & 0.32 & 1 & 6 & 2.75 & 9.0 & 0.46\\
\end{tabular}
\caption{Submission graph information}
\label{table:graphs}
\end{table}

\newpage
\begin{thebibliography}{9}

\bibitem{louvain}
Fast unfolding of communities in large networks, Vincent D Blondel, Jean-Loup Guillaume, Renaud Lambiotte, Renaud Lefebvre, Journal of Statistical Mechanics: Theory and Experiment 2008(10), P10008 (12pp)

\bibitem{networkx}
https://networkx.github.io/

\bibitem{community}
https://pypi.python.org/pypi/python-louvain/0.3

\bibitem{matplotlib}
http://matplotlib.org/

\bibitem{gambit}
http://www.gambit-project.org/gambit14/pyapi.html



\end{thebibliography}


\end{document}